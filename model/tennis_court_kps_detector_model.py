import syssys.path.append("../")import torchfrom torchvision.models import ViT_B_16_Weights, vit_b_16from data import get_tennis_kps_datasetif __name__ == "__main__":    device = "cpu"    # Creating the keypoint detection model.    model = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)    for param in model.parameters():        param.requires_grad = False    # replace the last layer of the pretrained ViT.    model.heads.head = torch.nn.Linear(in_features=768, out_features=14 * 2)  # 14 kps [x,y]    for param in model.heads.parameters():        param.requires_grad = True    # Load the train and validation loader.    train_loader, val_loader = get_tennis_kps_dataset()    criterion = torch.nn.MSELoss()    optimizer = torch.optim.Adam(params=model.parameters(), lr=3e-4)    # Number of epochs    epochs = 30    # Initialize the best loss to a high value    best_loss = float("inf")    for epoch in range(epochs):        total_loss = 0  # To accumulate the loss over the epoch        for i, (img, kps) in enumerate(train_loader):            img = img.to(device)            kps = kps.to(device)            optimizer.zero_grad()            pred = model(img)            loss = criterion(pred, kps)  # Compute the loss            loss.backward()            optimizer.step()            total_loss += loss.item()  # Accumulate the loss            if i % 20 == 0:                print(f"Epoch {epoch}, Iteration {i}, Loss {loss.item()}")        # Calculate the average loss for the epoch        avg_epoch_loss = total_loss / len(train_loader)        print(f"Epoch {epoch}, Average Loss {avg_epoch_loss}")        # Check if the average loss is less than the best loss so far        if avg_epoch_loss < best_loss:            best_loss = avg_epoch_loss  # Update the best loss            # Save the model checkpoint            checkpoint = {                "epoch": epoch,                "model_state_dict": model.state_dict(),                "optimizer_state_dict": optimizer.state_dict(),                "loss": avg_epoch_loss,            }            torch.save(checkpoint, f"checkpoint_epoch_{epoch}.pth")            print(f"Checkpoint saved at epoch {epoch} with average loss {avg_epoch_loss}")