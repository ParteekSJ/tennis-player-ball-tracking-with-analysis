import torchfrom torchvision import transformsfrom torchvision.models import resnet50, ResNet50_Weightsimport cv2class CourtKeypointsDetector:    def __init__(self, model_path):        # Initializing a pretrained ResNet50 Model        self.model = resnet50(weights=ResNet50_Weights.DEFAULT)        # Altering the last layer to predict the 28 (14x2) keypoints        self.model.fc = torch.nn.Linear(self.model.fc.in_features, 14 * 2)        # Loading the trained model weights into the initialized model        self.model.load_state_dict(torch.load(model_path, map_location="cpu"))        # Transformations for the images.        self.transforms = transforms.Compose(            [                transforms.ToPILImage(),                transforms.Resize((224, 224)),                transforms.ToTensor(),                transforms.Normalize(                    mean=[0.485, 0.456, 0.406],                    std=[0.229, 0.224, 0.225],                ),            ]        )    def predict(self, img):        """        Run the inference only on the first frame since keypoints won't change.        """        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)        image_tensor = self.transforms(img_rgb).unsqueeze(0)  # adding batch dim        with torch.no_grad():            outputs = self.model(image_tensor)        keypoints = outputs.squeeze().cpu().numpy()  # [14,2] -> [28,]        original_h, original_w = img_rgb.shape[:2]        # Transforming the keypoints to match the transformed image dimensions.        keypoints[::2] *= original_w / 224.0        keypoints[1::2] *= original_h / 224.0        return keypoints    def draw_keypoints(self, image, keypoints):        # Plot keypoints on the image        for i in range(0, len(keypoints), 2):            # Extracting a (x,y) keypoint pair            x, y = int(keypoints[i]), int(keypoints[i + 1])            cv2.putText(                image,                str(i // 2),                (x, y - 10),                cv2.FONT_HERSHEY_SIMPLEX,                0.5,                (0, 0, 255),                2,            )            cv2.circle(image, (x, y), 5, (0, 0, 255), -1)        # returning the annotated image.        return image    def draw_keypoints_on_video(self, video_frames, keypoints):        output_video_frames = []        for frame in video_frames:            frame = self.draw_keypoints(frame, keypoints)            output_video_frames.append(frame)        return output_video_frames